{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import huffman\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"este es un ejemplo de codificación de Huffman\"\n",
    "frequencies = Counter(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto codificado: 110 || 0100 || 111101 || 110 || 101 || 110 || 0100 || 101 || 0010 || 0111 || 101 || 110 || 111100 || 110 || 0011 || 00010 || 01010 || 0000 || 101 || 1110 || 110 || 101 || 0110 || 0000 || 1110 || 1001 || 1000 || 1001 || 0110 || 11111 || 0110 || 1001 || 00011 || 0111 || 101 || 1110 || 110 || 101 || 01011 || 0010 || 1000 || 1000 || 0011 || 11111 || 0111\n",
      "Texto decodificado: e\n"
     ]
    }
   ],
   "source": [
    "codigo_huffman = huffman.codebook(frequencies.items())\n",
    "texto_codificado = \" || \".join(codigo_huffman[char] for char in texto)\n",
    "\n",
    "print(\"Texto codificado:\", texto_codificado)\n",
    "\n",
    "# Paso 4: Decodificar el texto codificado\n",
    "# Crear un diccionario inverso para decodificar\n",
    "codigo_inverso = {v: k for k, v in codigo_huffman.items()}\n",
    "texto_decodificado = \"\"\n",
    "temp = \"\"\n",
    "for bit in texto_codificado:\n",
    "    temp += bit\n",
    "    if temp in codigo_inverso:\n",
    "        texto_decodificado += codigo_inverso[temp]\n",
    "        temp = \"\"\n",
    "\n",
    "print(\"Texto decodificado:\", texto_decodificado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, seq_length=40):\n",
    "    chars = sorted(set(text))\n",
    "    char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "    idx_to_char = {idx: ch for ch, idx in char_to_idx.items()}\n",
    "    vocab_size = len(chars)\n",
    "\n",
    "    # Crear secuencias de entrada y salida\n",
    "    input_seq = []\n",
    "    target_seq = []\n",
    "\n",
    "    for i in range(len(text) - seq_length):\n",
    "        in_seq = text[i : i + seq_length]\n",
    "        out_seq = text[i + seq_length]\n",
    "        input_seq.append([char_to_idx[char] for char in in_seq])\n",
    "        target_seq.append(char_to_idx[out_seq])\n",
    "\n",
    "    # Convertir listas de índices en matrices de entrada y salida adecuadas para el entrenamiento\n",
    "    input_seq = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        input_seq, maxlen=seq_length, padding=\"pre\"\n",
    "    )\n",
    "    target_seq = tf.keras.utils.to_categorical(target_seq, num_classes=vocab_size)\n",
    "\n",
    "    return input_seq, target_seq, vocab_size, char_to_idx, idx_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence shape: [[ 1  0  4 ... 15  8 16]\n",
      " [ 0  4  1 ...  8 16  1]\n",
      " [ 4  1  7 ... 16  1 22]\n",
      " ...\n",
      " [ 1 14  9 ... 18 18  5]\n",
      " [14  9  1 ... 18  5  6]\n",
      " [ 9  1  5 ...  5  6  5]]\n",
      "Target sequence shape: [[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "Vocabulary size: {0: '\\n', 1: ' ', 2: 'A', 3: 'P', 4: 'Y', 5: 'a', 6: 'b', 7: 'c', 8: 'd', 9: 'e', 10: 'g', 11: 'h', 12: 'i', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'z', 24: 'á', 25: 'é', 26: 'í'}\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcofura/anaconda3/envs/fundamentos_matematicos/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 1s - 132ms/step - accuracy: 0.1618 - loss: 3.2793\n",
      "Epoch 2/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.1863 - loss: 3.1925\n",
      "Epoch 3/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.1863 - loss: 2.9225\n",
      "Epoch 4/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.1912 - loss: 2.8323\n",
      "Epoch 5/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.1422 - loss: 2.7818\n",
      "Epoch 6/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 0.2157 - loss: 2.7413\n",
      "Epoch 7/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 0.1863 - loss: 2.7347\n",
      "Epoch 8/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 0.1863 - loss: 2.7149\n",
      "Epoch 9/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.1912 - loss: 2.6929\n",
      "Epoch 10/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 0.1961 - loss: 2.6745\n",
      "Epoch 11/100\n",
      "7/7 - 0s - 13ms/step - accuracy: 0.1961 - loss: 2.6526\n",
      "Epoch 12/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 0.1961 - loss: 2.6338\n",
      "Epoch 13/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 0.2451 - loss: 2.5988\n",
      "Epoch 14/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.2500 - loss: 2.5682\n",
      "Epoch 15/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.2941 - loss: 2.5319\n",
      "Epoch 16/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.3088 - loss: 2.4894\n",
      "Epoch 17/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.3039 - loss: 2.4495\n",
      "Epoch 18/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 0.3333 - loss: 2.3798\n",
      "Epoch 19/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.3578 - loss: 2.3306\n",
      "Epoch 20/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 0.3676 - loss: 2.2633\n",
      "Epoch 21/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.3922 - loss: 2.2106\n",
      "Epoch 22/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.3725 - loss: 2.1578\n",
      "Epoch 23/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.4069 - loss: 2.0736\n",
      "Epoch 24/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.4167 - loss: 2.0253\n",
      "Epoch 25/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.4216 - loss: 1.9771\n",
      "Epoch 26/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 0.4314 - loss: 1.8975\n",
      "Epoch 27/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.4804 - loss: 1.8377\n",
      "Epoch 28/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.4853 - loss: 1.7812\n",
      "Epoch 29/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.4853 - loss: 1.7178\n",
      "Epoch 30/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.5245 - loss: 1.6404\n",
      "Epoch 31/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.5196 - loss: 1.5937\n",
      "Epoch 32/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.5147 - loss: 1.5406\n",
      "Epoch 33/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.5539 - loss: 1.4793\n",
      "Epoch 34/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.5833 - loss: 1.4181\n",
      "Epoch 35/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.6127 - loss: 1.3527\n",
      "Epoch 36/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.6029 - loss: 1.2925\n",
      "Epoch 37/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.6078 - loss: 1.2499\n",
      "Epoch 38/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.6618 - loss: 1.2247\n",
      "Epoch 39/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.6618 - loss: 1.1522\n",
      "Epoch 40/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.7304 - loss: 1.0821\n",
      "Epoch 41/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.7451 - loss: 1.0135\n",
      "Epoch 42/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.7255 - loss: 0.9525\n",
      "Epoch 43/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.7990 - loss: 0.9007\n",
      "Epoch 44/100\n",
      "7/7 - 0s - 15ms/step - accuracy: 0.7843 - loss: 0.8587\n",
      "Epoch 45/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.8333 - loss: 0.7930\n",
      "Epoch 46/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.8480 - loss: 0.7196\n",
      "Epoch 47/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.8676 - loss: 0.6747\n",
      "Epoch 48/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.8775 - loss: 0.6248\n",
      "Epoch 49/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.8725 - loss: 0.5987\n",
      "Epoch 50/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.9363 - loss: 0.5435\n",
      "Epoch 51/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.9363 - loss: 0.4977\n",
      "Epoch 52/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.9608 - loss: 0.4630\n",
      "Epoch 53/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.9657 - loss: 0.4255\n",
      "Epoch 54/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.9804 - loss: 0.3951\n",
      "Epoch 55/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.9706 - loss: 0.3769\n",
      "Epoch 56/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.9657 - loss: 0.3671\n",
      "Epoch 57/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.9853 - loss: 0.3156\n",
      "Epoch 58/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.9951 - loss: 0.2924\n",
      "Epoch 59/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 0.9902 - loss: 0.2699\n",
      "Epoch 60/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.9951 - loss: 0.2432\n",
      "Epoch 61/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.9902 - loss: 0.2288\n",
      "Epoch 62/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.9902 - loss: 0.2154\n",
      "Epoch 63/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.9951 - loss: 0.1990\n",
      "Epoch 64/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.9951 - loss: 0.1811\n",
      "Epoch 65/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 0.9951 - loss: 0.1661\n",
      "Epoch 66/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.1540\n",
      "Epoch 67/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.1433\n",
      "Epoch 68/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.1316\n",
      "Epoch 69/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 1.0000 - loss: 0.1232\n",
      "Epoch 70/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.1153\n",
      "Epoch 71/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 1.0000 - loss: 0.1079\n",
      "Epoch 72/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 1.0000 - loss: 0.1018\n",
      "Epoch 73/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 1.0000 - loss: 0.0957\n",
      "Epoch 74/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0914\n",
      "Epoch 75/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0869\n",
      "Epoch 76/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0828\n",
      "Epoch 77/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0796\n",
      "Epoch 78/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 1.0000 - loss: 0.0757\n",
      "Epoch 79/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0712\n",
      "Epoch 80/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 1.0000 - loss: 0.0678\n",
      "Epoch 81/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 1.0000 - loss: 0.0653\n",
      "Epoch 82/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 1.0000 - loss: 0.0626\n",
      "Epoch 83/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0596\n",
      "Epoch 84/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0573\n",
      "Epoch 85/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 1.0000 - loss: 0.0547\n",
      "Epoch 86/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0527\n",
      "Epoch 87/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0502\n",
      "Epoch 88/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0488\n",
      "Epoch 89/100\n",
      "7/7 - 0s - 11ms/step - accuracy: 1.0000 - loss: 0.0469\n",
      "Epoch 90/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0457\n",
      "Epoch 91/100\n",
      "7/7 - 0s - 14ms/step - accuracy: 1.0000 - loss: 0.0440\n",
      "Epoch 92/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0424\n",
      "Epoch 93/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0414\n",
      "Epoch 94/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0396\n",
      "Epoch 95/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0385\n",
      "Epoch 96/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.0374\n",
      "Epoch 97/100\n",
      "7/7 - 0s - 9ms/step - accuracy: 1.0000 - loss: 0.0362\n",
      "Epoch 98/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0348\n",
      "Epoch 99/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0344\n",
      "Epoch 100/100\n",
      "7/7 - 0s - 10ms/step - accuracy: 1.0000 - loss: 0.0330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3130e3590>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de ejemplo\n",
    "text = \"\"\" Hola, ¿cómo estás? Soy un ejemplo de texto que se utilizará para entrenar un modelo de lenguaje.\n",
    "\"\"\"  \n",
    "seq_length = 10  \n",
    "input_seq, target_seq, vocab_size, char_to_idx, idx_to_char = preprocess_text(\n",
    "    text, seq_length\n",
    ")\n",
    "print(\"Input sequence shape:\", input_seq)\n",
    "print(\"Target sequence shape:\", target_seq)\n",
    "print(\"Vocabulary size:\", idx_to_char)\n",
    "# Construir el modelo\n",
    "model = Sequential(\n",
    "    [\n",
    "        Embedding(input_dim=vocab_size, output_dim=64, input_length=seq_length),\n",
    "        LSTM(128),\n",
    "        Dense(vocab_size, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(input_seq, target_seq, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "{'\\n': 2.4446226e-06, ' ': 0.00012292077, 'A': 3.9709444e-06, 'P': 0.00018478041, 'Y': 0.00021594099, 'a': 0.002025231, 'b': 0.0045404113, 'c': 2.0484175e-07, 'd': 4.2705764e-05, 'e': 0.9816928, 'g': 2.1880491e-07, 'h': 2.7613967e-05, 'i': 0.000121175595, 'l': 0.0043668956, 'm': 0.0023769338, 'n': 2.608391e-05, 'o': 5.560564e-06, 'q': 2.5820671e-05, 'r': 0.0002562776, 's': 0.0029980824, 't': 2.9368462e-05, 'u': 0.00015539383, 'v': 0.00076011376, 'z': 7.896544e-07, 'á': 5.8225937e-06, 'é': 1.0626007e-05, 'í': 1.7690279e-06}\n"
     ]
    }
   ],
   "source": [
    "def predict_next_char(model, input_text, char_to_idx, idx_to_char):\n",
    "    input_indices = [\n",
    "        char_to_idx[ch] for ch in input_text[-seq_length:]\n",
    "    ]  # Asegurarse de usar solo los últimos 'seq_length' caracteres\n",
    "    input_indices = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [input_indices], maxlen=seq_length, padding=\"pre\"\n",
    "    )\n",
    "    predictions = model.predict(input_indices)[0]\n",
    "    return {idx_to_char[i]: prob for i, prob in enumerate(predictions)}\n",
    "\n",
    "\n",
    "# Ejemplo de uso\n",
    "context = \"[]Hola\"\n",
    "predicted_probs = predict_next_char(model, context, char_to_idx, idx_to_char)\n",
    "print(predicted_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fundamentos_matematicos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
