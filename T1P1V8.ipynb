{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE  # SMOTE para aumento de datos\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  # Para la matriz de confusión\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Eliminar las columnas 'Breed2' y 'Color3'\n",
    "data = data.drop(columns=['Breed2', 'Color3'])\n",
    "\n",
    "# Separar características y etiqueta objetivo\n",
    "X = data.drop(columns=['AdoptionSpeed'])\n",
    "y = data['AdoptionSpeed']\n",
    "\n",
    "# Variables numéricas\n",
    "numeric_features = ['Age', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
    "                    'Sterilized', 'Health', 'Fee', 'PhotoAmt']\n",
    "\n",
    "# Variables categóricas para embeddings\n",
    "embedding_features = ['Breed1', 'Color1', 'Color2', 'State']\n",
    "\n",
    "# Variables categóricas para codificación one-hot\n",
    "onehot_features = ['Type', 'Gender']\n",
    "\n",
    "# Eliminar columnas que no aportan al modelo\n",
    "X = X.drop(columns=['Name', 'PetID'])\n",
    "\n",
    "# Reemplazar valores NaN por '-'\n",
    "X = X.fillna('-')\n",
    "\n",
    "# Codificar todas las variables categóricas (Label Encoding para embeddings, OneHot para otras)\n",
    "# Label Encoding para las variables categóricas que se usarán como embeddings\n",
    "for feature in embedding_features:\n",
    "    le = LabelEncoder()\n",
    "    X[feature] = le.fit_transform(X[feature].astype(str))  # Codificar todas las columnas de embeddings\n",
    "\n",
    "# One-Hot Encoding para variables como 'Type' y 'Gender'\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_onehot_encoded = onehot_encoder.fit_transform(X[onehot_features].astype(str))\n",
    "\n",
    "# Concatenar las variables numéricas con las variables codificadas\n",
    "X_combined = np.concatenate([X[numeric_features].values, X[embedding_features].values, X_onehot_encoded], axis=1)\n",
    "\n",
    "# Dividir el DataFrame en conjuntos de entrenamiento y validación\n",
    "X_train_combined, X_val_combined, y_train, y_val = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Aumento de Datos usando SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_combined, y_train)\n",
    "\n",
    "# Normalizar las características numéricas después del aumento de datos\n",
    "scaler = StandardScaler()\n",
    "X_train_numeric_resampled = scaler.fit_transform(X_train_resampled[:, :len(numeric_features)])\n",
    "X_val_numeric = scaler.transform(X_val_combined[:, :len(numeric_features)])\n",
    "\n",
    "# Preparar los datos de entrada para el modelo\n",
    "X_train_inputs_resampled = X_train_resampled\n",
    "\n",
    "# Crear las capas del modelo de Keras, utilizando las entradas de SMOTE\n",
    "numeric_input = Input(shape=(X_train_numeric_resampled.shape[1],), name='numeric_input')\n",
    "\n",
    "# Construir el modelo con regularización L2 y Dropout\n",
    "x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001))(numeric_input)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "# Capa de salida\n",
    "output = Dense(5, activation='softmax', name='output')(x)\n",
    "\n",
    "# Definir el modelo\n",
    "model = Model(inputs=numeric_input, outputs=output)\n",
    "\n",
    "# Compilar el modelo con categorical_crossentropy y accuracy\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convertir y_train_resampled e y_val a categorías (one-hot encoding para la salida)\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train_resampled, num_classes=5)\n",
    "y_val_cat = tf.keras.utils.to_categorical(y_val, num_classes=5)\n",
    "\n",
    "# Callback para Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Callback para ajustar el learning rate si el val_loss no mejora\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    x=X_train_numeric_resampled,\n",
    "    y=y_train_cat,\n",
    "    validation_data=(X_val_numeric, y_val_cat),\n",
    "    epochs=50,\n",
    "    batch_size=80,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Graficar la pérdida (loss) por época\n",
    "plt.plot(history.history['loss'], label='Pérdida en entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida en validación')\n",
    "plt.title('Pérdida por época')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida (Loss)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Graficar la precisión (accuracy) por época\n",
    "plt.plot(history.history['accuracy'], label='Precisión en entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Precisión en validación')\n",
    "plt.title('Precisión por época')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisión (Accuracy)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ---- Matriz de confusión ----\n",
    "# Hacer predicciones sobre el conjunto de validación\n",
    "y_val_pred = model.predict(X_val_numeric)\n",
    "\n",
    "# Convertir las predicciones de probabilidades a etiquetas\n",
    "y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "\n",
    "# Generar la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred_classes)\n",
    "\n",
    "# Visualizar la matriz de confusión\n",
    "confusion_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "confusion_display.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
